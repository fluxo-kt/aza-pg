#!/usr/bin/env bun
/**
 * pgflow Schema Generator
 *
 * Fetches and combines all pgflow schema files from a specific GitHub tag
 * into a single SQL file for use in tests.
 *
 * Usage:
 *   bun scripts/pgflow/generate-schema.ts 0.9.0
 *   bun scripts/pgflow/generate-schema.ts 0.9.0 --update-install
 *   bun scripts/pgflow/generate-schema.ts 0.9.0 --dry-run
 *
 * Options:
 *   --update-install  Also update install.ts version constant and file path
 *   --dry-run         Show what would be done without writing files
 *   --verbose         Show detailed progress
 */

import { join, dirname } from "node:path";
import { fileURLToPath } from "node:url";
import { format as formatSql } from "sql-formatter";

const __dirname = dirname(fileURLToPath(import.meta.url));
const ROOT_DIR = join(__dirname, "../..");
const FIXTURES_DIR = join(ROOT_DIR, "tests/fixtures/pgflow");
const INSTALL_TS = join(FIXTURES_DIR, "install.ts");
const SQL_FORMATTER_CONFIG = join(ROOT_DIR, ".sql-formatter.json");

async function loadSqlFormatterConfig(): Promise<Record<string, unknown>> {
  try {
    const configFile = Bun.file(SQL_FORMATTER_CONFIG);
    return await configFile.json();
  } catch {
    // Fallback to sensible defaults matching project conventions
    return {
      language: "postgresql",
      tabWidth: 2,
      useTabs: false,
      keywordCase: "upper",
    };
  }
}

// Schema files in the order they should be concatenated
const SCHEMA_FILES = [
  "0010_extensions.sql",
  "0020_schemas.sql",
  "0030_utilities.sql",
  "0040_types.sql",
  "0050_tables_definitions.sql",
  "0055_tables_workers.sql",
  "0060_tables_runtime.sql",
  "0090_function_poll_for_tasks.sql",
  "0100_function_add_step.sql",
  "0100_function_cascade_complete_taskless_steps.sql",
  "0100_function_complete_task.sql",
  "0100_function_create_flow.sql",
  "0100_function_fail_task.sql",
  "0100_function_maybe_complete_run.sql",
  "0100_function_start_flow.sql",
  "0100_function_start_ready_steps.sql",
  "0105_function_get_run_with_states.sql",
  "0110_function_set_vt_batch.sql",
  "0110_function_start_flow_with_states.sql",
  "0120_function_start_tasks.sql",
  "0200_grants_and_revokes.sql",
] as const;

interface Options {
  version: string;
  tag: string;
  updateInstall: boolean;
  dryRun: boolean;
  verbose: boolean;
}

function parseArgs(): Options {
  const args = process.argv.slice(2);
  const version = args.find((a) => !a.startsWith("--"));

  if (!version) {
    console.error("Usage: bun scripts/pgflow/generate-schema.ts <version> [options]");
    console.error("");
    console.error("Examples:");
    console.error("  bun scripts/pgflow/generate-schema.ts 0.9.0");
    console.error("  bun scripts/pgflow/generate-schema.ts 0.9.0 --update-install");
    console.error("  bun scripts/pgflow/generate-schema.ts 0.9.0 --dry-run --verbose");
    process.exit(1);
  }

  // Normalize version (remove 'v' prefix if present)
  const normalizedVersion = version.replace(/^v/, "");
  const tag = `pgflow@${normalizedVersion}`;

  return {
    version: normalizedVersion,
    tag,
    updateInstall: args.includes("--update-install"),
    dryRun: args.includes("--dry-run"),
    verbose: args.includes("--verbose"),
  };
}

function getSchemaUrl(tag: string, filename: string): string {
  const encodedTag = encodeURIComponent(tag);
  return `https://raw.githubusercontent.com/pgflow-dev/pgflow/${encodedTag}/pkgs/core/schemas/${filename}`;
}

async function fetchSchemaFile(tag: string, filename: string, verbose: boolean): Promise<string> {
  const url = getSchemaUrl(tag, filename);

  if (verbose) {
    console.log(`  Fetching: ${filename}`);
  }

  const response = await fetch(url);

  if (!response.ok) {
    throw new Error(
      `Failed to fetch ${filename}: ${response.status} ${response.statusText}\n  URL: ${url}`
    );
  }

  const content = await response.text();

  // Validate that we got actual SQL content, not an error page
  if (content.includes("<!DOCTYPE html>") || content.includes("<html")) {
    throw new Error(`Received HTML instead of SQL for ${filename} - tag may not exist`);
  }

  return content;
}

async function fetchAllSchemas(tag: string, verbose: boolean): Promise<Map<string, string>> {
  const schemas = new Map<string, string>();

  console.log(`Fetching ${SCHEMA_FILES.length} schema files from ${tag}...`);

  for (const filename of SCHEMA_FILES) {
    const content = await fetchSchemaFile(tag, filename, verbose);
    schemas.set(filename, content);
  }

  console.log(`‚úÖ Fetched all ${schemas.size} files`);
  return schemas;
}

function generateCombinedSchema(version: string, schemas: Map<string, string>): string {
  const header = `-- pgflow v${version} Schema
-- Source: https://github.com/pgflow-dev/pgflow/tree/pgflow@${version}/pkgs/core/schemas/
-- Generated by: bun scripts/pgflow/generate-schema.ts ${version}
-- Generated at: ${new Date().toISOString()}
-- Combined from ${schemas.size} individual schema files
`;

  const sections: string[] = [header];

  for (const filename of SCHEMA_FILES) {
    const content = schemas.get(filename);
    if (!content) {
      throw new Error(`Missing content for ${filename}`);
    }

    sections.push(`-- ============================================================================
-- Source: ${filename}
-- ============================================================================
${content.trim()}

`);
  }

  return sections.join("\n");
}

async function updateInstallTs(version: string, dryRun: boolean, verbose: boolean): Promise<void> {
  const content = await Bun.file(INSTALL_TS).text();

  // Update PGFLOW_VERSION constant
  const versionPattern = /export const PGFLOW_VERSION = "[^"]+"/;
  const schemaPattern = /const SCHEMA_FILE = join\(__dirname, "schema-v[^"]+\.sql"\)/;

  let newContent = content.replace(versionPattern, `export const PGFLOW_VERSION = "${version}"`);
  newContent = newContent.replace(
    schemaPattern,
    `const SCHEMA_FILE = join(__dirname, "schema-v${version}.sql")`
  );

  if (newContent === content) {
    console.log("‚ÑπÔ∏è  install.ts already up to date");
    return;
  }

  if (dryRun) {
    console.log(`Would update install.ts with version ${version}`);
    if (verbose) {
      console.log("  - PGFLOW_VERSION constant");
      console.log("  - SCHEMA_FILE path");
    }
    return;
  }

  await Bun.write(INSTALL_TS, newContent);
  console.log(`‚úÖ Updated install.ts to v${version}`);
}

async function findOldSchemas(currentVersion: string): Promise<string[]> {
  const glob = new Bun.Glob("schema-v*.sql");
  const files: string[] = [];

  for await (const file of glob.scan(FIXTURES_DIR)) {
    if (!file.includes(`v${currentVersion}`)) {
      files.push(file);
    }
  }

  return files;
}

async function main(): Promise<void> {
  const options = parseArgs();

  console.log("‚ïê".repeat(70));
  console.log(`pgflow Schema Generator - v${options.version}`);
  console.log("‚ïê".repeat(70));
  console.log(`Tag: ${options.tag}`);
  console.log(`Dry run: ${options.dryRun}`);
  console.log(`Update install.ts: ${options.updateInstall}`);
  console.log("‚ïê".repeat(70));
  console.log("");

  // Fetch all schema files
  const schemas = await fetchAllSchemas(options.tag, options.verbose);

  // Generate combined schema
  const combinedSchema = generateCombinedSchema(options.version, schemas);
  const outputPath = join(FIXTURES_DIR, `schema-v${options.version}.sql`);

  console.log("");
  console.log(
    `Combined schema: ${combinedSchema.length} bytes, ${combinedSchema.split("\n").length} lines`
  );

  // Validate key v0.9.0+ indicators if version >= 0.9.0
  const versionParts = options.version.split(".").map(Number);
  const major = versionParts[0] ?? 0;
  const minor = versionParts[1] ?? 0;
  if (major > 0 || (major === 0 && minor >= 9)) {
    console.log("");
    console.log("Validating v0.9.0+ schema indicators...");

    const schemaLower = combinedSchema.toLowerCase();
    const checks = [
      {
        name: "read_with_poll removed",
        pass: !schemaLower.includes("read_with_poll"),
        fail: "read_with_poll should not exist in v0.9.0+",
      },
      {
        name: "set_vt_batch returns table",
        pass: schemaLower.includes("set_vt_batch") && schemaLower.includes("returns table"),
        fail: "set_vt_batch should return TABLE format in v0.9.0+",
      },
      {
        name: "headers column present",
        pass: schemaLower.includes("headers jsonb"),
        fail: "headers JSONB column should be present for pgmq 1.5.1 compatibility",
      },
    ];

    let allPassed = true;
    for (const check of checks) {
      if (check.pass) {
        console.log(`  ‚úÖ ${check.name}`);
      } else {
        console.log(`  ‚ùå ${check.name}: ${check.fail}`);
        allPassed = false;
      }
    }

    if (!allPassed) {
      console.error("\n‚ùå Schema validation failed - content may not match expected version");
      process.exit(1);
    }
  }

  // Write schema file
  if (options.dryRun) {
    console.log("");
    console.log("Dry run - would write:");
    console.log(`  ${outputPath}`);
  } else {
    // Write raw schema first
    await Bun.write(outputPath, combinedSchema);
    console.log(`\n‚úÖ Written: ${outputPath}`);

    // Format the schema file with sql-formatter for consistency
    console.log("üìù Formatting schema with sql-formatter...");
    const sqlConfig = await loadSqlFormatterConfig();
    const rawContent = await Bun.file(outputPath).text();
    const formattedContent = formatSql(rawContent, sqlConfig);
    await Bun.write(outputPath, formattedContent);
    console.log("‚úÖ Schema formatted");
  }

  // Update install.ts if requested
  if (options.updateInstall) {
    console.log("");
    await updateInstallTs(options.version, options.dryRun, options.verbose);
  }

  // List old schema files that could be deleted
  const oldSchemas = await findOldSchemas(options.version);
  if (oldSchemas.length > 0) {
    console.log("");
    console.log("Old schema files that can be deleted:");
    for (const file of oldSchemas) {
      console.log(`  rm ${join(FIXTURES_DIR, file)}`);
    }
  }

  console.log("");
  console.log("‚ïê".repeat(70));
  console.log("Next steps:");
  console.log("  1. Review the generated schema");
  console.log("  2. Run: bun run validate");
  console.log("  3. Run: bun run test:pgflow");
  if (oldSchemas.length > 0) {
    console.log(`  4. Delete old schema files if tests pass`);
  }
  console.log("‚ïê".repeat(70));
}

main().catch((error) => {
  console.error("\n‚ùå Error:", error.message);
  process.exit(1);
});
